<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Blog Series</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Introduction to Neural Networks</strong></a>
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/jamesalexanderbradshaw/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
									</ul>
								</header>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Background</h2>
									</header>
									<div class="content">
										<p>Deep Learning, like several emerging approaches in Machine Learning, draws inspiration from nature, particularly the human brain. With an estimated 10^11 neurons communicating via electrical signals, the brain's functionality is intricate. Neurons interact through synapses, determining which neurons activate others and the signal strength. Decision-making and action-taking processes originate in the mind, with responses stemming from numerous neuron interactions, informed by past experiences to determine optimal next steps. Neural networks are constructed based on this principle. Deep Learning stands out as the first Machine Learning framework to surpass human performance across various tasks. Its premise is straightforward: emulate brain functions and harness computational power to exceed the brain's capabilities.<br><br>
											Deep Learning models not only increase the number of parameters, often referred to as 'nodes' in DL, but also enhance the depth of the architectures that process this data. Rather than a model comprising a single layer of 10,000 nodes, consider a structure with a layer of 100 nodes passing to another layer of 100 nodes, where each pair between the two layers is interconnected. In both cases, the network essentially handles 10,000 different parameters. However, in the second example, a more intricate trend is assumed, contingent upon specific outcomes aligning to recognise a pattern.<br><br>
											3Blue1Brown offers an insightful video on this topic, which is highly recommended. They suggest that employing a Deep Learning architecture would benefit a model aiming to learn the underlying trend behind the MNIST Handwritten Digits dataset. For instance, identifying a closed loop pattern might signify that the digit is a 0, 6, 8, or 9. However, if there is also a tail end, this could indicate that the digit is a 1, 2, 3, 4, 5, 6, 7, or 9. If separate parameters are learned for each of these scenarios, high weights might be assigned to digits that are unlikely to be the true label. However, by incorporating a parameter that assigns a high value to digits with both a closed loop and a tail end, a more specific pattern is targeted, reducing the likelihood of overconfidence in incorrect classes.<p>
									</div>
								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Home</a></li>
										<li><a href="about-me.html">About Me</a></li>
										<li>
											<span class="opener">Research Contributions</span>
											<ul>
												<li><a href="#">Advancing Predictive Toxicology</a></li>
												<li><a href="#">Graph-based methods for microscopy image analysis</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Blog Series</span>
											<ul>
												<li><a href="introduction-to-neural-networks.html">Introduction to Neural Networks</a></li>
											</ul>
										</li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Feel free to reach out for collaborations, discussions, or just to say hello!</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">jamesalexanderbradshaw@gmail.com</a></li>
										<li class="icon solid fa-home">London, United Kingdom</li>
									</ul>
								</section>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>